1. *Feature Learning*
  * [Learning Feature Representations with K-means](http://www.cs.stanford.edu/~acoates/papers/coatesng_nntot2012.pdf) by Adam Coates and Andrew Y. Ng 
  * [The devil is in the details: an evaluation of recent feature encoding methods](http://www.robots.ox.ac.uk/~vgg/publications/2011/Chatfield11/chatfield11.pdf) by Chatfield et. al. 
  * [Emergence of Object-Selective Features in Unsupervised Feature Learning](http://www.cs.stanford.edu/~acoates/papers/coateskarpathyng_nips2012.pdf) by Coates, Ng
  * [Scaling Learning Algorithms towards AI](http://yann.lecun.com/exdb/publis/pdf/bengio-lecun-07.pdf) Benjio & LeCun
  * [A Theory of Feature Learning](http://arxiv.org/abs/1504.00083) by Brendan van Rooyen, Robert C. Williamson

2. *Deep Learning*
  * [Dropout: A Simple Way to Prevent Neural Networks from Overfitting](http://www.cs.toronto.edu/~rsalakhu/papers/srivastava14a.pdf) by Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever and Ruslan Salakhutdinov
  * [Understanding the difficulty of training deep feedforward neural networks](http://jmlr.org/proceedings/papers/v9/glorot10a/glorot10a.pdf) by Xavier Glorot and Yoshua Bengio
  * [Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift](http://arxiv.org/abs/1502.03167) by Sergey Ioffe and Christian Szegedy
  * [Deep Learning in Neural Networks: An Overview](http://arxiv.org/pdf/1404.7828v4.pdf) by Jurgen Schmidhuber
  * [Qualitatively characterizing neural network optimization problems](http://arxiv.org/abs/1412.6544) by Ian J. Goodfellow, Oriol Vinyals
  * [Scaling Learning Algorithms towards AI](http://yann.lecun.com/exdb/publis/pdf/bengio-lecun-07.pdf) by Yann LeCun and Yoshua Benjio
  * [Efficient Backprop](http://yann.lecun.com/exdb/publis/pdf/lecun-98b.pdf) by LeCun, Bottou et al
  * [Towards Biologically Plausible Deep Learning](http://arxiv.org/abs/1502.04156) by Yoshua Bengio, Dong-Hyun Lee, Jorg Bornschein, Zhouhan Lin
  * [A Probabilistic Theory of Deep Learning](http://arxiv.org/pdf/1504.00641v1.pdf) by Ankit B. Patel, Tan Nguyen, Richard G. Baraniuk
  * [ImageNet Classification with Deep Convolutional Neural Networks](http://www.cs.toronto.edu/~fritz/absps/imagenet.pdf) by Krizhevsky, Sutskever and Hinton
  * [Text Understanding from Scratch](http://arxiv.org/abs/1502.01710) by Xiang Zhang, Yann LeCun
  * [Learning Deep Architectures for AI](http://www.iro.umontreal.ca/~bengioy/papers/ftml_book.pdf) by Yoshua Bengio
  * [Deep Learning - a review article that appeared in Nature](http://sci-hub.org/downloads/d397/lecun2015.pdf) by Yann LeCun, Yoshua Bengio & Geoffrey Hinton
  * [Very deep convolutional networks for large scale image recognition](http://arxiv.org/pdf/1409.1556.pdf) by Karen Simonyan & Andrew Zisserman 

3. *Recurrent Neural Nets*
  * [On the difficulty of training Recurrent Neural Networks](http://arxiv.org/pdf/1211.5063v2.pdf) by Razvan Pascanu, Tomas Mikolov and Yoshua Bengio
  * [Training Recurrent Neural Networks](http://www.cs.utoronto.ca/~ilya/pubs/ilya_sutskever_phd_thesis.pdf) Phd thesis of Ilya Sutskever
  * [A Critical Review of Recurrent Neural Networks for Sequence Learning](http://arxiv.org/pdf/1506.00019v1.pdf) by Zachary C. Lipton
  * [On Recurrent and Deep Neural Networks](http://www-etud.iro.umontreal.ca/~pascanur/papers/thesis.pdf) Phd thesis of Razvan Pascanu
  * [Gradient-Based Learning Algorithms for Recurrent Networks and Their Computational Complexity](https://web.stanford.edu/class/psych209a/ReadingsByDate/02_25/Williams%20Zipser95RecNets.pdf) by Ronald J. Williams and David Zipser
  
4. *Scalable Machine Learning*
  * [Bring the Noise: Embracing Randomness is the Key to Scaling Up Machine Learning Algorithms](http://online.liebertpub.com/doi/pdf/10.1089/big.2013.0010) by Brian Delssandro
  * [Large Scale Machine Learning with Stochastic Gradient Descent](http://leon.bottou.org/publications/pdf/compstat-2010.pdf) by Leon Bottou
  * [The TradeOffs of Large Scale Learning](http://papers.nips.cc/paper/3323-the-tradeoffs-of-large-scale-learning.pdf) by Leon Bottou & Olivier Bousquet
  * [Hash Kernels for Structured Data](http://www.jmlr.org/papers/volume10/shi09a/shi09a.pdf) by Qinfeng Shi et. al.
  * [Feature Hashing for Large Scale Multitask Learning](http://arxiv.org/pdf/0902.2206.pdf) by Weinberger et. al.
  * [Large-Scale Learning with Less RAM via Randomization](http://www.eecs.tufts.edu/~dsculley/papers/round-model-icml.pdf) by a group of authors from Google
  * [Collaborative Email-Spam Filtering with the Hashing-Trick](http://ceas.cc/2009/papers/ceas2009-paper-11.pdf) by Joshua Attenberg et. al.

5. *Gradient based Training*
  * [Practical Recommendations for Gradient-Based Training of Deep Architectures](http://arxiv.org/pdf/1206.5533v2.pdf) by Yoshua Bengio
  * [Stochastic Gradient Descent Tricks](http://research.microsoft.com/pubs/192769/tricks-2012.pdf) by L´eon Bottou
  * [Accelerating Stochastic Gradient Descent via Online Learning to Sample](http://arxiv.org/pdf/1506.09016v1.pdf) by Guillaume Bouchard, Theo Trouillon, Julien Perez, Adrien Gaidon
  * [Train faster, generalize better: Stability of stochastic gradient descent](http://arxiv.org/abs/1509.01240#) by Moritz Hardt, Benjamin Recht, Yoram Singer

6. *Non Linear Units*
  * [Rectified Linear Units Improve Restricted Boltzmann Machines](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.165.6419&rep=rep1&type=pdf) by Nair & Hinton
  * [Mathematical Intuition for Performance of Rectified Linear Unit in Deep Neural Networks](https://www.academia.edu/7826776/Mathematical_Intuition_for_Performance_of_Rectified_Linear_Unit_in_Deep_Neural_Networks) by Alexandre Dalyec

7. *Interesting blog posts and presentations*
  * [Hacker''s Guide to Neural Networks](https://karpathy.github.io/neuralnets/) by Andrej Karpathy
  * [Breaking Linear Classifiers on ImageNet](http://karpathy.github.io/2015/03/30/breaking-convnets/) by Andrej Karpathy
  * [Classifying plankton with Deep Neural Networks](http://benanne.github.io/2015/03/17/plankton.html)
  * [Deep stuff about deep learning?](https://blogs.princeton.edu/imabandit/2015/03/20/deep-stuff-about-deep-learning/)
  * [Understanding Convolution in Deep Learning](https://timdettmers.wordpress.com/2015/03/26/convolution-deep-learning/)
  * [A Brief Overview of Deep Learning](http://yyue.blogspot.in/2015/01/a-brief-overview-of-deep-learning.html) by Ilya Sutskever
  * [Recurrent Neural Networks for Collaborative Filtering](http://erikbern.com/?p=589)
  * [Deep Belief Networks vs Convolutional Neural Networks](http://stackoverflow.com/questions/24545725/deep-belief-networks-vs-convolutional-neural-networks)
  * [Deep Learning vs Probabilistic Graphical Models vs Logic](http://quantombone.blogspot.in/2015/04/deep-learning-vs-probabilistic.html)
  * [Extracting Structured Data From Recipes Using Conditional Random Fields](http://open.blogs.nytimes.com/2015/04/09/extracting-structured-data-from-recipes-using-conditional-random-fields/?_r=0)
  * [Ten Lessons Learned from Building (real-life impactful) Machine Learning Systems](http://technocalifornia.blogspot.in/2014/12/ten-lessons-learned-from-building-real.html)
  * [Scalable Machine Learning](http://de.slideshare.net/mikiobraun/scalable-machine-learning-47862907) by Mikio L Braun
  * [The Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/) by Andrej Karpathy
  * [Initialization of deep networks](http://deepdish.io/2015/02/24/network-initialization/)
  * [Weak Learning, Boosting, and the AdaBoost algorithm](http://jeremykun.com/2015/05/18/boosting-census/)
  * [Probably Approximately Correct — a Formal Theory of Learning](http://jeremykun.com/2014/01/02/probably-approximately-correct-a-formal-theory-of-learning/)
  * [Making sense of principal component analysis, eigenvectors & eigenvalues](http://stats.stackexchange.com/questions/2691/making-sense-of-principal-component-analysis-eigenvectors-eigenvalues)
  * [A Step by Step Backpropagation example](http://mattmazur.com/2015/03/17/a-step-by-step-backpropagation-example/)
  * [Covariance Matrices and Data Distributions](https://theclevermachine.wordpress.com/2013/03/29/covariance-matrices-and-data-distributions/)
  * [The Statistical Whitening Transform](https://theclevermachine.wordpress.com/2013/03/30/the-statistical-whitening-transform/)
  * [Machine Learning Summer School 2014 @ CMU - the complete playlist](https://www.youtube.com/playlist?list=PLZSO_6-bSqHQCIYxE3ycGLXHMjK3XV7Iz)
  * [Machine Learning Summer School 2011 @ Purdue - the complete playlist](https://www.youtube.com/playlist?list=PL2A65507F7D725EFB)
  * [Calculus on Computational Graphs: Backpropagation](http://colah.github.io/posts/2015-08-Backprop/)
  * [On chain rule, computational graphs, and backpropagation](http://outlace.com/Computational-Graph/)
  * [Understanding Convolutions](http://colah.github.io/posts/2014-07-Understanding-Convolutions/)
  * [Understanding LSTM Networks](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)
  * [Conv Nets: A Modular Perspective](http://colah.github.io/posts/2014-07-Conv-Nets-Modular/)
  * [Demystifying LSTM neural networks](http://blog.terminal.com/demistifying-long-short-term-memory-lstm-recurrent-neural-networks/)
  * [Crash course on Learning Theory Part 1](https://blogs.princeton.edu/imabandit/2015/10/13/crash-course-on-learning-theory-part-1/)
  * [Crash course on Learning Theory Part 2](https://blogs.princeton.edu/imabandit/2015/10/22/crash-course-on-learning-theory-part-2/)

8. *Interesting courses and tutorials* 
  * [CS231n: Convolutional Neural Networks for Visual Recognition](http://cs231n.stanford.edu/) at Stanford by Andrej Karpathy
  * [CS224d: Deep Learning for Natural Language Processing](http://cs224d.stanford.edu/) at Stanford by Richard Socher
  * [STA 4273H (Winter 2015): Large Scale Machine Learning](http://www.cs.toronto.edu/~rsalakhu/STA4273_2015/) at Toronto by Russ Salakhutdinov
  * [AM 207 Monte Carlo Methods, Stochastic Optimization](http://am207.org/) at Harvard by Verena Kaynig-Fittkau and Pavlos Protopapas 
  * [ACL 2012 + NAACL 2013 Tutorial: Deep Learning for NLP (without Magic)](http://www.socher.org/index.php/DeepLearningTutorial/DeepLearningTutorial) at NAACL 2013 by Richard Socher, Chris Manning and Yoshua Bengio
  * [Video course on Deep Learning](https://www.youtube.com/playlist?list=PL6Xpj9I5qXYEcOhn7TqghAJ6NAPrNmUBH) by Hugo Larochelle
  * [ECCV-2010 Tutorial: Feature Learning for Image Classification](http://ufldl.stanford.edu/eccv10-tutorial/) by Kai Yu & Andrew Ng
  * [Kdd 2014 Tutorial - the recommender problem revisited](http://www.slideshare.net/xamat/kdd-2014-tutorial-the-recommender-problem-revisited) by Xavier Amatriain
  * [Machine Learning 2014-15 at Oxford University](https://www.cs.ox.ac.uk/people/nando.defreitas/machinelearning/)
  * [Course Notes - Stanford Machine Learning by Andrew Ng](http://www.holehouse.org/mlclass/index.html)
  * [Statistical Machine Learning](https://www.youtube.com/playlist?list=PLjbUi5mgii6BWEUZf7He6nowWvGne_Y8r) by Larry Wasserman
  * [Machine Learning for Computer Vision](http://www.computervisiontalks.com/tag/ml-for-computer-vision-course/) by Rudolph Triebel
  * [MIT Machine Learning Fall 2004](http://www.ai.mit.edu/courses/6.867-f04/lectures.html)
  * [MIT Machine Learning Fall 2006](http://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-867-machine-learning-fall-2006/)
  * [CMU Statistical Machine Learning Spring 2015 by Tibshirani & Wasserman](http://www.stat.cmu.edu/~larry/=sml/)
  * [CMU Machine Learning Spring 2015 by Alex Smola](http://www.computervisiontalks.com/tag/machine-learning-class-10-701/)
  * [IISc Statistical Learning Theory Fall 2013 by Shivani Agarwal](http://www.shivani-agarwal.net/Teaching/E0370/Aug-2013/index.html)

9. *General*
  * [Distilling the Knowledge in a Neural Network](http://arxiv.org/abs/1503.02531) by Geoffrey Hinton, Oriol Vinyals, Jeff Dean
  * [A Random Forest Guided Tour](http://www.lsta.upmc.fr/BIAU/bs.pdf) by Biau & Scornet
  * [Understanding Random Forests - From Theory to Practice](http://arxiv.org/pdf/1407.7502v3.pdf) by Gilles Louppe

10. *MCMC and Variational Inference*
  * [Markov Chain Monte Carlo Without all the Bullshit](http://jeremykun.com/2015/04/06/markov-chain-monte-carlo-without-all-the-bullshit/)
  * [How would you explain Markov Chain Monte Carlo (MCMC) to a layperson?](http://stats.stackexchange.com/questions/165/how-would-you-explain-markov-chain-monte-carlo-mcmc-to-a-layperson)
  * [iTunes The Data Skeptic Podcast](https://itunes.apple.com/us/podcast/mini-markov-chain-monte-carlo/id890348705?i=339051856&mt=2)
  * [An Introduction to MCMC for Machine Learning](http://www.cs.ubc.ca/~arnaud/andrieu_defreitas_doucet_jordan_intromontecarlomachinelearning.pdf) by Christophe Andrieu, Nando De Freitas, Arnaud Daucet and Michael Jordan
  * [The Markov Chain Monte Carlo Revolution](http://statweb.stanford.edu/~cgates/PERSI/papers/MCMCRev.pdf) by Persi Diaconis
  * [A Tutorial on Variational Inference presented at ICML 2015](http://shakirm.com/papers/VITutorial.pdf) by Shakir Mohamed
  * [MCMC - The Gibbs Sampler](https://theclevermachine.wordpress.com/2012/11/05/mcmc-the-gibbs-sampler/)
 
11. *Conditional Random Fields*
  * [Log-linear Models and Conditional Random Fields](http://videolectures.net/cikm08_elkan_llmacrf/) by Charles Elkan (video)
  * [Log-linear models and conditional random fields - notes](http://www.cs.columbia.edu/~smaskey/CS6998-0412/supportmaterial/cikmtutorial.pdf) by Charles Elkan
  * [Conditional Random Fields - pointers](http://www.inference.phy.cam.ac.uk/hmw26/crf/) by Hanna M Wallach
  * [Machine Learning for Sequential Data: A Review](http://web.engr.oregonstate.edu/~tgd/publications/mlsd-ssspr.pdf) by Thomas G. Dietterich
  * [An Introduction to Conditional Random Fields](http://homepages.inf.ed.ac.uk/csutton/publications/crftutv2.pdf) by Charles Sutton and Andrew McCallum

12. *Topic Models*
  * [Probabilistic Topic Models](https://www.cs.princeton.edu/~blei/papers/Blei2012.pdf) by David M Blei
  * [Visualizing Topic Models](http://ajbc.io/projects/papers/ChaneyBlei2012.pdf) by Allison J.B. Chaney and David M. Blei
  * [Latent Dirichlet Allocation](http://www.cs.stanford.edu/people/ang//papers/nips01-lda.pdf) by Blei, Ng and Jordan
  * [Latent Dirichlet Allocation](http://www.jmlr.org/papers/volume3/blei03a/blei03a.pdf) by Blei, Ng and Jordan
  * [Automatic Topic Modelling with LDA](http://engineering.intenthq.com/2015/02/automatic-topic-modelling-with-lda/)

13. *Principal Component Analysis*
  * [A Tutorial on Principal Components Analysis](http://www.cs.otago.ac.nz/cosc453/student_tutorials/principal_components.pdf) by Lindsay I Smith
  * [A Tutorial on Principal Components Analysis](http://arxiv.org/pdf/1404.1100.pdf) by Jonathon Shlens (they call it the best)

14. *Reinforcement Learning*
  * [Demystifying Deep Reinforcement Learning](http://neuro.cs.ut.ee/demystifying-deep-reinforcement-learning/) by Tambet Matiisen
  * [Deep Reinforcement Learning with Neon](http://neuro.cs.ut.ee/deep-reinforcement-learning-with-neon/) by Tambet Matiisen